{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371c76d6",
   "metadata": {},
   "source": [
    "#### Today we solve a problem related to computer vision\n",
    "\n",
    "# Computer Vision:\n",
    "\n",
    "Computer vision is a field of artificial intelligence that trains computers to interpret and understand the visual world. Using digital images from cameras and videos and deep learning models, machines can accurately identify and classify objects — and then react to what they “see.”\n",
    "\n",
    "\n",
    "#### Libraries for computer vision\n",
    "\n",
    "1) torch\n",
    "\n",
    "2) torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e287ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec31d0",
   "metadata": {},
   "source": [
    "# 1) Load Dataset (FashionMNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb3d56c",
   "metadata": {},
   "source": [
    "To download it, we provide the following parameters:\n",
    "\n",
    "root: str - which folder do you want to download the data to?\n",
    "    \n",
    "train: Bool - do you want the training or test split?\n",
    "\n",
    "download: Bool - should the data be downloaded?\n",
    "\n",
    "transform: torchvision.transforms - what transformations would you like to do on the data?\n",
    "\n",
    "target_transform - you can transform the targets (labels) if you like too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4102928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.FashionMNIST(\n",
    "    root=\"fashionmnist\",\n",
    "    train=True, \n",
    "    download=True, \n",
    "    transform=ToTensor(), \n",
    "    target_transform=None \n",
    ")\n",
    "\n",
    "\n",
    "test = datasets.FashionMNIST(\n",
    "    root=\"fashionmnist\",\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0caa9f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = train[0]\n",
    "image.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebd23a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size of data\n",
    "\n",
    "len(train), len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfeead5",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.numpy().reshape(28,28))\n",
    "plt.title(label);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d703f0",
   "metadata": {},
   "source": [
    "# 2) Prepare Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d6e1dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x00000214EBB69700>, <torch.utils.data.dataloader.DataLoader object at 0x00000214F41A8E80>)\n",
      "Length of train dataloader: 1875 batches of 32\n",
      "Length of test dataloader: 313 batches of 32\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True \n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False \n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e530f8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 28, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015cd704",
   "metadata": {},
   "source": [
    "# 3) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb7d1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTModel0(nn.Module):\n",
    "    def __init__(self,input_shape,hidden_units,output_shape):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units), # in_features = number of features in a data sample (784 pixels)\n",
    "            nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape)\n",
    "        )\n",
    "        \n",
    "    def forward(self,data):\n",
    "        return self.layer_stack(data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f99259ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train.classes\n",
    "\n",
    "model_0 = FashionMNISTModel0(input_shape=784, # one for every pixel (28x28)\n",
    "    hidden_units=10,\n",
    "    output_shape=len(class_names) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c9daf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and loss function\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4110aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() \n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3280bdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch Loss: 2.392350912094116 and Accuracy: 0.0033333333333333335 \n",
      "Train batch Loss: 284.5870056152344 and Accuracy: 10.433333333333334 \n",
      "Train batch Loss: 474.440673828125 and Accuracy: 22.768333333333334 \n",
      "Train batch Loss: 645.0167236328125 and Accuracy: 35.45333333333333 \n",
      "Train batch Loss: 809.6401977539062 and Accuracy: 48.31166666666667 \n",
      "Train batch Loss: 971.3385620117188 and Accuracy: 61.24166666666667 \n",
      "Train batch Loss: 1134.1739501953125 and Accuracy: 74.11 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 0 Loss: 0.6263759732246399, Accuracy: 77.325, Val_loss: 0.5245091915130615, Val_Accuracy: 81.47963258785943\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 0.24139608442783356 and Accuracy: 0.04666666666666667 \n",
      "Train batch Loss: 152.02468872070312 and Accuracy: 13.188333333333333 \n",
      "Train batch Loss: 305.626708984375 and Accuracy: 26.226666666666667 \n",
      "Train batch Loss: 454.1046142578125 and Accuracy: 39.45333333333333 \n",
      "Train batch Loss: 598.4390869140625 and Accuracy: 52.81166666666667 \n",
      "Train batch Loss: 746.5335693359375 and Accuracy: 66.035 \n",
      "Train batch Loss: 889.2633056640625 and Accuracy: 79.36666666666666 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 1 Loss: 0.4935123026371002, Accuracy: 82.61666666666666, Val_loss: 0.49934515357017517, Val_Accuracy: 82.61781150159744\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 0.3740919232368469 and Accuracy: 0.045 \n",
      "Train batch Loss: 144.2318572998047 and Accuracy: 13.355 \n",
      "Train batch Loss: 284.2845458984375 and Accuracy: 26.651666666666667 \n",
      "Train batch Loss: 424.88037109375 and Accuracy: 40.0 \n",
      "Train batch Loss: 565.7589111328125 and Accuracy: 53.36833333333333 \n",
      "Train batch Loss: 704.727783203125 and Accuracy: 66.72333333333333 \n",
      "Train batch Loss: 848.6700439453125 and Accuracy: 79.95333333333333 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 2 Loss: 0.47049251198768616, Accuracy: 83.26, Val_loss: 0.5556245446205139, Val_Accuracy: 79.69249201277955\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 0.6083084344863892 and Accuracy: 0.043333333333333335 \n",
      "Train batch Loss: 142.85951232910156 and Accuracy: 13.393333333333333 \n",
      "Train batch Loss: 282.8685302734375 and Accuracy: 26.73 \n",
      "Train batch Loss: 420.7686767578125 and Accuracy: 40.163333333333334 \n",
      "Train batch Loss: 552.1598510742188 and Accuracy: 53.745 \n",
      "Train batch Loss: 687.0277709960938 and Accuracy: 67.205 \n",
      "Train batch Loss: 820.8483276367188 and Accuracy: 80.68166666666667 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 3 Loss: 0.45496708154678345, Accuracy: 84.03, Val_loss: 0.4747387170791626, Val_Accuracy: 83.66613418530352\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 0.580375075340271 and Accuracy: 0.045 \n",
      "Train batch Loss: 133.1844482421875 and Accuracy: 13.631666666666666 \n",
      "Train batch Loss: 267.2922058105469 and Accuracy: 27.083333333333332 \n",
      "Train batch Loss: 408.19073486328125 and Accuracy: 40.44166666666667 \n",
      "Train batch Loss: 545.6644287109375 and Accuracy: 53.931666666666665 \n",
      "Train batch Loss: 680.6103515625 and Accuracy: 67.36333333333333 \n",
      "Train batch Loss: 810.4617919921875 and Accuracy: 80.93666666666667 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 4 Loss: 0.4499094486236572, Accuracy: 84.26, Val_loss: 0.46686941385269165, Val_Accuracy: 83.53634185303514\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 0.3834529221057892 and Accuracy: 0.04666666666666667 \n",
      "Train batch Loss: 133.409912109375 and Accuracy: 13.518333333333333 \n",
      "Train batch Loss: 270.564208984375 and Accuracy: 26.968333333333334 \n",
      "Train batch Loss: 400.8587341308594 and Accuracy: 40.498333333333335 \n",
      "Train batch Loss: 532.1919555664062 and Accuracy: 54.053333333333335 \n",
      "Train batch Loss: 662.8511962890625 and Accuracy: 67.58833333333334 \n",
      "Train batch Loss: 796.123046875 and Accuracy: 81.065 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 5 Loss: 0.44194135069847107, Accuracy: 84.39666666666666, Val_loss: 0.4781225621700287, Val_Accuracy: 83.20686900958466\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 0.3484857976436615 and Accuracy: 0.04666666666666667 \n",
      "Train batch Loss: 127.39456939697266 and Accuracy: 13.721666666666666 \n",
      "Train batch Loss: 260.789794921875 and Accuracy: 27.19 \n",
      "Train batch Loss: 389.2628479003906 and Accuracy: 40.75666666666667 \n",
      "Train batch Loss: 519.61328125 and Accuracy: 54.28333333333333 \n",
      "Train batch Loss: 653.1393432617188 and Accuracy: 67.82166666666667 \n",
      "Train batch Loss: 787.8616333007812 and Accuracy: 81.32666666666667 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 6 Loss: 0.4369331896305084, Accuracy: 84.695, Val_loss: 0.4782477021217346, Val_Accuracy: 83.47643769968052\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 0.24905270338058472 and Accuracy: 0.05 \n",
      "Train batch Loss: 130.548095703125 and Accuracy: 13.563333333333333 \n",
      "Train batch Loss: 258.65045166015625 and Accuracy: 27.218333333333334 \n",
      "Train batch Loss: 386.518310546875 and Accuracy: 40.875 \n",
      "Train batch Loss: 519.4403076171875 and Accuracy: 54.36 \n",
      "Train batch Loss: 647.7966918945312 and Accuracy: 67.91166666666666 \n",
      "Train batch Loss: 779.8850708007812 and Accuracy: 81.42833333333333 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 7 Loss: 0.4328499138355255, Accuracy: 84.79166666666667, Val_loss: 0.5145621299743652, Val_Accuracy: 82.01876996805112\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 0.7257646322250366 and Accuracy: 0.041666666666666664 \n",
      "Train batch Loss: 130.2294464111328 and Accuracy: 13.62 \n",
      "Train batch Loss: 255.6390838623047 and Accuracy: 27.26 \n",
      "Train batch Loss: 387.6371765136719 and Accuracy: 40.861666666666665 \n",
      "Train batch Loss: 516.8948364257812 and Accuracy: 54.498333333333335 \n",
      "Train batch Loss: 646.8851318359375 and Accuracy: 68.05 \n",
      "Train batch Loss: 773.8672485351562 and Accuracy: 81.62166666666667 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 8 Loss: 0.42973750829696655, Accuracy: 84.965, Val_loss: 0.4616101086139679, Val_Accuracy: 83.72603833865814\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 0.1979866772890091 and Accuracy: 0.04833333333333333 \n",
      "Train batch Loss: 129.2543487548828 and Accuracy: 13.585 \n",
      "Train batch Loss: 258.10906982421875 and Accuracy: 27.1 \n",
      "Train batch Loss: 385.6553649902344 and Accuracy: 40.71666666666667 \n",
      "Train batch Loss: 512.791015625 and Accuracy: 54.37833333333333 \n",
      "Train batch Loss: 642.1728515625 and Accuracy: 67.96666666666667 \n",
      "Train batch Loss: 771.5575561523438 and Accuracy: 81.60333333333334 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 9 Loss: 0.4280102252960205, Accuracy: 84.975, Val_loss: 0.4733113646507263, Val_Accuracy: 83.19688498402556\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now its time for training loop\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "total_train_loss = []\n",
    "total_test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_batch_loss = 0\n",
    "    train_batch_acc = 0\n",
    "    \n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        \n",
    "        #forward pass\n",
    "        y_pred = model_0(X)\n",
    "        \n",
    "        #Calculate loss\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        train_batch_loss += loss\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        train_batch_acc += accuracy_fn(y,y_pred.argmax(dim=1))\n",
    "        \n",
    "        \n",
    "        # Optimizer zero grad\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Loss Backward\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 300==0:\n",
    "            print(f\"Train batch Loss: {train_batch_loss} and Accuracy: {train_batch_acc/len(train_dataloader)} \")\n",
    "        \n",
    "        \n",
    "    total_train_loss.append(train_batch_loss/len(train_dataloader)) # Average the loss on batces\n",
    "    train_acc.append(train_batch_acc/len(train_dataloader))\n",
    "    \n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_batch_loss = 0\n",
    "        test_batch_acc = 0\n",
    "        for X, y in test_dataloader:\n",
    "            test_pred = model_0(X)\n",
    "            \n",
    "            test_batch_loss += loss_fn(test_pred,y)\n",
    "            test_batch_acc += accuracy_fn(y,test_pred.argmax(dim=1))\n",
    "        \n",
    "        total_test_loss.append(test_batch_loss/len(test_dataloader))\n",
    "        test_acc.append(test_batch_acc/len(test_dataloader))\n",
    "        \n",
    "    print('----------------------------------------------------------------------\\n')\n",
    "    print(f'Epoch {epoch} Loss: {train_batch_loss/len(train_dataloader)}, Accuracy: {train_batch_acc/len(train_dataloader)}, Val_loss: {test_batch_loss/len(test_dataloader)}, Val_Accuracy: {test_batch_acc/len(test_dataloader)}')\n",
    "    print('----------------------------------------------------------------------\\n')\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7fc982",
   "metadata": {},
   "source": [
    "## Now lets create a CNN based Model for classifying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37c35e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNIST_CNN(nn.Module):\n",
    "    def __init__(self,input_channel,hidden_units,output_shape):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=input_channel,out_channels=hidden_units\n",
    "                              ,kernel_size=3,stride=1,padding=1)\n",
    "        \n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1)\n",
    "        \n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(in_features=hidden_units*7*7,out_features=output_shape)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        \n",
    "        X = self.conv1(X)\n",
    "        X = self.relu1(X)\n",
    "        X = self.pool1(X)\n",
    "        X = self.conv2(X)\n",
    "        X = self.relu2(X)\n",
    "        X = self.pool2(X)\n",
    "        X = self.flatten(X)\n",
    "        X = self.linear(X)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5825880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer and loss function\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a591a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here hidden_units also refereing to channels of output feature maps from conv2d\n",
    "model_1 = FashionMNIST_CNN(input_channel=1,hidden_units=64,\\\n",
    "                          output_shape=len(class_names))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ac03fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batch Loss: 2.327446460723877 and Accuracy: 0.0 \n",
      "Train batch Loss: 695.8174438476562 and Accuracy: 1.4766666666666666 \n",
      "Train batch Loss: 1389.3365478515625 and Accuracy: 3.13 \n",
      "Train batch Loss: 2082.8076171875 and Accuracy: 4.748333333333333 \n",
      "Train batch Loss: 2776.32373046875 and Accuracy: 6.283333333333333 \n",
      "Train batch Loss: 3469.78955078125 and Accuracy: 7.85 \n",
      "Train batch Loss: 4163.10546875 and Accuracy: 9.438333333333333 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 0 Loss: 2.311635732650757, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 2.309089422225952 and Accuracy: 0.008333333333333333 \n",
      "Train batch Loss: 695.858154296875 and Accuracy: 1.5366666666666666 \n",
      "Train batch Loss: 1389.4171142578125 and Accuracy: 3.0366666666666666 \n",
      "Train batch Loss: 2082.84375 and Accuracy: 4.628333333333333 \n",
      "Train batch Loss: 2776.350830078125 and Accuracy: 6.195 \n",
      "Train batch Loss: 3469.7548828125 and Accuracy: 7.781666666666666 \n",
      "Train batch Loss: 4163.2861328125 and Accuracy: 9.388333333333334 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 1 Loss: 2.3116374015808105, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 2.295321464538574 and Accuracy: 0.008333333333333333 \n",
      "Train batch Loss: 695.8483276367188 and Accuracy: 1.5833333333333333 \n",
      "Train batch Loss: 1389.4241943359375 and Accuracy: 3.098333333333333 \n",
      "Train batch Loss: 2082.886962890625 and Accuracy: 4.715 \n",
      "Train batch Loss: 2776.122802734375 and Accuracy: 6.365 \n",
      "Train batch Loss: 3469.76171875 and Accuracy: 7.888333333333334 \n",
      "Train batch Loss: 4163.2685546875 and Accuracy: 9.365 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 2 Loss: 2.311638116836548, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 2.291206121444702 and Accuracy: 0.011666666666666667 \n",
      "Train batch Loss: 695.7974853515625 and Accuracy: 1.5166666666666666 \n",
      "Train batch Loss: 1389.3214111328125 and Accuracy: 3.025 \n",
      "Train batch Loss: 2082.698486328125 and Accuracy: 4.64 \n",
      "Train batch Loss: 2776.1083984375 and Accuracy: 6.22 \n",
      "Train batch Loss: 3469.705810546875 and Accuracy: 7.791666666666667 \n",
      "Train batch Loss: 4163.279296875 and Accuracy: 9.396666666666667 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 3 Loss: 2.3116374015808105, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 2.3007307052612305 and Accuracy: 0.006666666666666667 \n",
      "Train batch Loss: 695.736328125 and Accuracy: 1.625 \n",
      "Train batch Loss: 1389.460693359375 and Accuracy: 3.1133333333333333 \n",
      "Train batch Loss: 2082.869873046875 and Accuracy: 4.655 \n",
      "Train batch Loss: 2776.350830078125 and Accuracy: 6.255 \n",
      "Train batch Loss: 3469.838623046875 and Accuracy: 7.838333333333333 \n",
      "Train batch Loss: 4163.23876953125 and Accuracy: 9.445 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 4 Loss: 2.311638593673706, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 2.3158600330352783 and Accuracy: 0.0016666666666666668 \n",
      "Train batch Loss: 695.9493408203125 and Accuracy: 1.5016666666666667 \n",
      "Train batch Loss: 1389.2088623046875 and Accuracy: 3.1616666666666666 \n",
      "Train batch Loss: 2082.78271484375 and Accuracy: 4.723333333333334 \n",
      "Train batch Loss: 2776.099853515625 and Accuracy: 6.391666666666667 \n",
      "Train batch Loss: 3469.578125 and Accuracy: 7.935 \n",
      "Train batch Loss: 4163.2099609375 and Accuracy: 9.423333333333334 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 5 Loss: 2.3116369247436523, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 2.321115493774414 and Accuracy: 0.0033333333333333335 \n",
      "Train batch Loss: 695.6898803710938 and Accuracy: 1.55 \n",
      "Train batch Loss: 1389.2420654296875 and Accuracy: 3.095 \n",
      "Train batch Loss: 2082.529052734375 and Accuracy: 4.748333333333333 \n",
      "Train batch Loss: 2775.81982421875 and Accuracy: 6.34 \n",
      "Train batch Loss: 3469.4736328125 and Accuracy: 7.851666666666667 \n",
      "Train batch Loss: 4163.1279296875 and Accuracy: 9.436666666666667 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 6 Loss: 2.3116374015808105, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 2.3098692893981934 and Accuracy: 0.011666666666666667 \n",
      "Train batch Loss: 695.7472534179688 and Accuracy: 1.605 \n",
      "Train batch Loss: 1389.4256591796875 and Accuracy: 3.1133333333333333 \n",
      "Train batch Loss: 2082.875732421875 and Accuracy: 4.65 \n",
      "Train batch Loss: 2776.324462890625 and Accuracy: 6.15 \n",
      "Train batch Loss: 3469.626708984375 and Accuracy: 7.763333333333334 \n",
      "Train batch Loss: 4163.21240234375 and Accuracy: 9.39 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 7 Loss: 2.3116393089294434, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 2.3238487243652344 and Accuracy: 0.0033333333333333335 \n",
      "Train batch Loss: 695.7938232421875 and Accuracy: 1.6116666666666666 \n",
      "Train batch Loss: 1389.1807861328125 and Accuracy: 3.158333333333333 \n",
      "Train batch Loss: 2082.815185546875 and Accuracy: 4.6883333333333335 \n",
      "Train batch Loss: 2776.430908203125 and Accuracy: 6.251666666666667 \n",
      "Train batch Loss: 3470.092041015625 and Accuracy: 7.831666666666667 \n",
      "Train batch Loss: 4163.345703125 and Accuracy: 9.408333333333333 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 8 Loss: 2.3116371631622314, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Train batch Loss: 2.3113300800323486 and Accuracy: 0.005 \n",
      "Train batch Loss: 696.12744140625 and Accuracy: 1.5466666666666666 \n",
      "Train batch Loss: 1389.532958984375 and Accuracy: 3.065 \n",
      "Train batch Loss: 2082.974853515625 and Accuracy: 4.675 \n",
      "Train batch Loss: 2776.461669921875 and Accuracy: 6.273333333333333 \n",
      "Train batch Loss: 3470.123046875 and Accuracy: 7.773333333333333 \n",
      "Train batch Loss: 4163.34716796875 and Accuracy: 9.43 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Epoch 9 Loss: 2.3116397857666016, Accuracy: 9.788333333333334, Val_loss: 2.31148099899292, Val_Accuracy: 9.994009584664537\n",
      "----------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now its time for training loop\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "total_train_loss = []\n",
    "total_test_loss = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_batch_loss = 0\n",
    "    train_batch_acc = 0\n",
    "    \n",
    "    for batch, (X,y) in enumerate(train_dataloader):\n",
    "        model_1.train()\n",
    "        \n",
    "        #forward pass\n",
    "        y_pred = model_1(X)\n",
    "        \n",
    "        #Calculate loss\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        train_batch_loss += loss\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        train_batch_acc += accuracy_fn(y,y_pred.argmax(dim=1))\n",
    "        \n",
    "        \n",
    "        # Optimizer zero grad\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Loss Backward\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # Update weights\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 300==0:\n",
    "            print(f\"Train batch Loss: {train_batch_loss} and Accuracy: {train_batch_acc/len(train_dataloader)} \")\n",
    "        \n",
    "        \n",
    "    total_train_loss.append(train_batch_loss/len(train_dataloader)) # Average the loss on batces\n",
    "    train_acc.append(train_batch_acc/len(train_dataloader))\n",
    "    \n",
    "    model_1.eval()\n",
    "    with torch.inference_mode():\n",
    "        test_batch_loss = 0\n",
    "        test_batch_acc = 0\n",
    "        for X, y in test_dataloader:\n",
    "            test_pred = model_1(X)\n",
    "            \n",
    "            test_batch_loss += loss_fn(test_pred,y)\n",
    "            test_batch_acc += accuracy_fn(y,test_pred.argmax(dim=1))\n",
    "        \n",
    "        total_test_loss.append(test_batch_loss/len(test_dataloader))\n",
    "        test_acc.append(test_batch_acc/len(test_dataloader))\n",
    "        \n",
    "    print('----------------------------------------------------------------------\\n')\n",
    "    print(f'Epoch {epoch} Loss: {train_batch_loss/len(train_dataloader)}, Accuracy: {train_batch_acc/len(train_dataloader)}, Val_loss: {test_batch_loss/len(test_dataloader)}, Val_Accuracy: {test_batch_acc/len(test_dataloader)}')\n",
    "    print('----------------------------------------------------------------------\\n')\n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c9d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
